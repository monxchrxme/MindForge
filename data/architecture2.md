Это подробное описание архитектуры вашей системы **Educational Quiz Generator**, обновленное с учетом всех последних улучшений стабильности (Merge Strategy, Safe JSON, Change Type Filtering).

***

# Архитектура системы: AI-Orchestrator & FactCheck

Система построена на паттерне **Multi-Agent System**, где центральный Оркестратор управляет потоком данных между специализированными агентами (Parser, FactCheck, Quiz).

## 1. Глобальная диаграмма потоков (Pipeline)

Весь процесс обработки заметки (`process_note_pipeline`) в `OrchestratorAgent` выглядит так:

```mermaid
graph TD
    A[Входной текст] --> B{Анализ типа (LLM)}
    B -->|Code/Theory| C[Стратегия: Code/Standard]
    B -->|Short/List| D[Стратегия: Direct Quiz]
    
    C --> E{Проверка Кэша}
    E -->|Есть кэш| F[Загрузка Verified Concepts]
    E -->|Нет кэша| G[ParserAgent]
    
    G --> H[Extracted Concepts]
    H --> I[FactCheckAgent]
    
    I --> J{Merge & Validate}
    J -->|Verified Concepts| K[Сохранение в Кэш]
    J -->|Corrections Report| L[Логирование и Отчет UI]
    
    F --> M[QuizAgent]
    K --> M
    D --> M
    
    M --> N[Генерация вопросов]
    N --> O[Vector History (Deduplication)]
    O --> P[Готовый Квиз]
```

***

## 2. Детальное описание компонентов

### A. OrchestratorAgent (Мозг системы)
**Задача:** Координация, управление состоянием сессии, кэширование, сбор отчетов.

1.  **Анализ контента:** Определяет, содержит ли заметка код (`ContentType.CODE`). Если да — включает стратегию `code_practice`.
2.  **Управление кэшем:**
    *   Ключ кэша = `hash(raw_text)`.
    *   В кэше хранятся уже **проверенные** (verified) концепты. Это экономит токены на парсинг и фактчек.
3.  **Сбор отчета:** Хранит `self.corrections_report`, который заполняется Фактчекером, и передает его на фронтенд для отображения уведомлений ("Мы исправили ошибку в определении...").

### B. ParserAgent (Добытчик)
**Задача:** Превратить сырой текст в структуру, не потеряв сложные данные (код).

*   **Стратегия `code_practice`:**
    *   Использует "жадный" промпт для извлечения: `Term`, `Definition`, `CodeSnippet`.
    *   **Важно:** Ищет код в JSON-ответе по разным ключам (`code`, `snippet`, `code_snippet`), так как LLM может своевольничать.
*   **Результат:** Список "грязных" концептов. Код здесь — сырая строка из текста пользователя.

### C. FactCheckAgent (Ревизор) — *Самый сложный компонент*
**Задача:** Проверить факты и связь "Код <-> Теория", не сломав JSON-структуру.

**Используемый паттерн: "Blind Validation & Merge Strategy"**

1.  **Вход:** Список концептов (Термин + Определение + Код).
2.  **Промпт (Safe Context):**
    *   Код экранируется (`{` -> `{{`) и подается в промпт для *контекста*.
    *   **Инструкция LLM:** "Проверь определение. Если код не подходит, напиши `[CODE_ERROR]` в определение. Укажи `change_type`. **Не возвращай сам код в JSON**".
3.  **JSON Ответ LLM:**
    ```json
    {
      "term": "Конструктор",
      "definition": "Исправленное определение...",
      "change_type": "minor" 
    }
    ```
    *Почему так:* Мы не гоняем C++/Python код внутри JSON-значений, чтобы избежать ошибок парсинга (`Expecting ',' delimiter`).

4.  **Логика слияния (Merge Logic) на Python:**
    *   Скрипт берет `definition` из ответа LLM.
    *   Скрипт берет `code_snippet` из **Оригинала** (входных данных).
    *   **Обработка ошибок кода:** Если в `definition` найден маркер `[CODE_ERROR]`, скрипт:
        1.  Удаляет маркер из текста.
        2.  Принудительно ставит `code_snippet = None`.
        3.  Фиксирует ошибку для отчета.

5.  **Фильтрация отчета:**
    *   Использует поле `change_type` от LLM.
    *   `none` / `minor` -> Игнорируем (или пишем в debug).
    *   `major` -> Добавляем в `corrections_report` (показываем юзеру Warning).

### D. QuizAgent (Генератор)
**Задача:** Создать вопросы на основе чистых данных.

*   Получает на вход список `verified_concepts`.
*   Если стратегия `code_practice`, генерирует вопросы типа "Что выведет этот код?" или "Найди ошибку", используя сохраненный `code_snippet`.

***

## 3. Структуры данных

### Concept (Внутреннее представление)
```python
{
    "term": "Конструктор копирования",
    "definition": "Специальный конструктор для создания нового объекта как копии существующего.",
    "code_snippet": "ClassName(const ClassName &other) { ... }" // Или None
}
```

### Corrections Report (Отчет об исправлениях)
Формируется Фактчекером, отдается на фронтенд.
```python
[
    {
        "term": "Деструктор",
        "type": "definition_fix",
        "message": "Существенная правка определения.",
        "original": "Функция удаления.",
        "fixed": "Специальный метод класса, вызываемый при уничтожении объекта для освобождения ресурсов."
    },
    {
        "term": "Полиморфизм",
        "type": "code_mismatch",
        "message": "Код не соответствует термину и был удален.",
        "removed_code": "int a = 5;" // Код, который был ошибочно привязан
    }
]
```

***

## 4. Преимущества этой архитектуры

1.  **JSON-Safe:** Система полностью защищена от падений из-за спецсимволов в коде пользователя, так как код никогда не генерируется внутри JSON-ответов LLM.
2.  **Умная фильтрация шума:** Благодаря `change_type`, пользователь не получает спам из уведомлений, если LLM просто переставила слова местами.
3.  **Целостность данных:** Проверка связи "Код-Определение" работает (LLM видит код), но сам код не портится (мы берем оригинал).
4.  **Прозрачность:** Пользователь всегда знает, если AI "вмешался" в его конспект и исправил смысловую ошибку.

Источники
